{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d538a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Needed Dependencies\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.utils.validation import check_array\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4147d57",
   "metadata": {},
   "source": [
    "# Creating Model To Train Data Using Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f2e62",
   "metadata": {},
   "source": [
    "## Loading \"ETL_credit_data.csv\" Into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7041656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reference to CSV file\n",
    "RL_url = \"https://nextcloud.unknowntunnel.com/s/ybcswYZDTBWi3Nx/download/ETL_credit_data.csv\"\n",
    "\n",
    "# Import the CSV into a pandas DataFrame\n",
    "LR_credit_data_df = pd.read_csv(RL_url)\n",
    "\n",
    "# Display dataframe\n",
    "LR_credit_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8767f621",
   "metadata": {},
   "source": [
    "### Create the labels set (`y`)  from the “loan_status” column, and then create the features (`X`) DataFrame from the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into labels and features\n",
    "# Separate the y variable, the labels\n",
    "LR_y = LR_credit_data_df['Bankruptcies']\n",
    "\n",
    "# Separate the X variable, the features\n",
    "LR_X = LR_credit_data_df.drop(columns='Bankruptcies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0369623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the y variable Series\n",
    "LR_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf2600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the X variable DataFrame\n",
    "LR_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94682e2",
   "metadata": {},
   "source": [
    "### Check the balance of the labels variable (`y`) by using the `value_counts` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911471c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of our target values\n",
    "LR_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd545c1",
   "metadata": {},
   "source": [
    "### Split the data into training and testing datasets by using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data using train_test_split\n",
    "# Assign a random_state of 1 to the function\n",
    "LR_X_train, LR_X_test, LR_y_train, LR_y_test = train_test_split(LR_X, \n",
    "                                                    LR_y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=LR_y)\n",
    "LR_X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b44090d",
   "metadata": {},
   "source": [
    "## Create a Logistic Regression Model with the Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edab114",
   "metadata": {},
   "source": [
    "###  Fit a logistic regression model by using the training data (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d6ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "Log_Reg_Model = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)\n",
    "Log_Reg_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d82aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using training data\n",
    "Log_Reg_Model.fit(LR_X_train, LR_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55091895",
   "metadata": {},
   "source": [
    "### Save the predictions on the testing data labels by using the testing feature data (`X_test`) and the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f787c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction using the testing data\n",
    "Log_Reg_Model_Predictions = Log_Reg_Model.predict(LR_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37793e2",
   "metadata": {},
   "source": [
    "### Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7434a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "confusion_matrix(LR_y_test, Log_Reg_Model_Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7364a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the testing data accuracy score\n",
    "LR_acc_score = accuracy_score(LR_y_test, Log_Reg_Model_Predictions)\n",
    "\n",
    "# Print testing data accuracy score\n",
    "print(f\"Testing Data Accuracy Score: {LR_acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed780e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Classification Report\n",
    "target_names = [\"Loan Not Defaulted\", \"Loan Defaulted\"]\n",
    "print(classification_report(LR_y_test, Log_Reg_Model_Predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d43dcb",
   "metadata": {},
   "source": [
    "## Predict a Logistic Regression Model with Resampled Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e4f52",
   "metadata": {},
   "source": [
    "### Use the `RandomOverSampler` module from the imbalanced-learn library to resample the data. Be sure to confirm that the labels have an equal number of data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7de959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the random oversampler model\n",
    "# # Assign a random_state parameter of 1 to the model\n",
    "ROS = RandomOverSampler(random_state = 1)\n",
    "\n",
    "# Fit the original training data to the random_oversampler model\n",
    "X_ROS, y_ROS = ROS.fit_resample(LR_X_train, LR_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the distinct values of the resampled labels data\n",
    "y_ROS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af2f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "Log_Reg_ROS = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)\n",
    "Log_Reg_ROS\n",
    "\n",
    "# Fit the model using the resampled training data\n",
    "Log_Reg_ROS.fit(X_ROS, y_ROS)\n",
    "\n",
    "# Make a prediction using the testing data\n",
    "Log_Reg_ROS_Predictions = Log_Reg_ROS.predict(LR_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef17702",
   "metadata": {},
   "source": [
    "### Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "confusion_matrix(LR_y_test, Log_Reg_ROS_Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e372c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the testing data accuracy score\n",
    "LR_testing_acc_score = accuracy_score(LR_y_test, Log_Reg_ROS_Predictions)\n",
    "\n",
    "# Print testing data accuracy score\n",
    "print(f\"Testing Data Accuracy Score: {LR_testing_acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af023600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Precision Score Averages of the testing data\n",
    "LR_testing_prec_score = precision_score(LR_y_test, Log_Reg_ROS_Predictions, average=None)\n",
    "\n",
    "# Print Precision Score Averages of the testing data\n",
    "print(f\"Testing Data Precision Score Averages: {LR_testing_prec_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb4af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Recall Score Averages of the testing data\n",
    "LR_testing_rec_score = recall_score(LR_y_test, Log_Reg_ROS_Predictions, average=None)\n",
    "\n",
    "# Print Recall Score Averages of the testing data\n",
    "print(f\"Testing Data Recall Score Averages: {LR_testing_rec_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Classification Report\n",
    "LR_target_names = [\"Loan Not Defaulted\", \"Loan Defaulted\"]\n",
    "print(classification_report(LR_y_test, Log_Reg_ROS_Predictions, target_names=LR_target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73079702",
   "metadata": {},
   "source": [
    "# Creating Model To Train Data Using Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0f104",
   "metadata": {},
   "source": [
    "## Reloading \"ETL_credit_data.csv\" Into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reference to CSV file\n",
    "RF_url = \"https://nextcloud.unknowntunnel.com/s/ybcswYZDTBWi3Nx/download/ETL_credit_data.csv\"\n",
    "\n",
    "# Import the CSV into a pandas DataFrame\n",
    "RF_credit_data_df = pd.read_csv(RF_url)\n",
    "\n",
    "# Display dataframe\n",
    "RF_credit_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397ade4c",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19160c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set\n",
    "RF_X = RF_credit_data_df.copy()\n",
    "RF_X.drop(\"Bankruptcies\", axis=1, inplace=True)\n",
    "RF_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target vector\n",
    "RF_y = RF_credit_data_df[\"Bankruptcies\"].ravel()\n",
    "RF_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "RF_X_train, RF_X_test, RF_y_train, RF_y_test = train_test_split(RF_X, RF_y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a39b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Standard Scaller\n",
    "X_scaler = scaler.fit(RF_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e99030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(RF_X_train)\n",
    "X_test_scaled = X_scaler.transform(RF_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d9a7fc",
   "metadata": {},
   "source": [
    "## Fitting the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f158e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f11708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, RF_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b510ee1",
   "metadata": {},
   "source": [
    "## Making Predictions Using the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a323d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "RF_testing_predictions = rf_model.predict(X_test_scaled)\n",
    "RF_testing_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc55660a",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "confusion_matrix(RF_y_test, RF_testing_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the testing data accuracy score\n",
    "RF_testing_acc_score = accuracy_score(RF_y_test, RF_testing_predictions)\n",
    "\n",
    "# Print testing data accuracy score\n",
    "print(f\"Testing Data Accuracy Score: {RF_testing_acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3960673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Precision Score Averages of the testing data\n",
    "RF_testing_prec_score = precision_score(RF_y_test, RF_testing_predictions, average=None)\n",
    "\n",
    "# Print Precision Score Averages of the testing data\n",
    "print(f\"Testing Data Precision Score Averages: {RF_testing_prec_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Recall Score Averages of the testing data\n",
    "RF_testing_rec_score = recall_score(RF_y_test, RF_testing_predictions, average=None)\n",
    "\n",
    "# Print Recall Score Averages of the testing data\n",
    "print(f\"Testing Data Recall Score Averages: {RF_testing_rec_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef444ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Classification Report\n",
    "RF_target_names = [\"Loan Not Defaulted\", \"Loan Defaulted\"]\n",
    "print(classification_report(RF_y_test, RF_testing_predictions, target_names=RF_target_names))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
